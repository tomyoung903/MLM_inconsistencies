{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and global utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nus-ytj/miniconda3/envs/inconsistencies/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''imports'''\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from itertools import combinations\n",
    "import random\n",
    "import pickle\n",
    "from utils import general_utils, eoc\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer, T5Tokenizer\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from typing import Tuple, List\n",
    "import torch.nn.functional as F\n",
    "import eoc_datasets\n",
    "from model_configs import model_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nus-ytj/miniconda3/envs/inconsistencies/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-11b automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify model and load tokenizer\n",
    "# model_identifier = \"google-ul2\"\n",
    "model_identifier = \"t5-11b\" \n",
    "# model_identifier = \"flan-ul2\"\n",
    "\n",
    "config = model_configs[model_identifier]\n",
    "\n",
    "model_name, model_dir, mode, no_extra_tokens, model_kwargs = \\\n",
    "    config['model_name'], config['model_dir'], config['mode'], config['no_extra_tokens'], config['model_kwargs']\n",
    "\n",
    "# Use custom huggingface cache dirs in case the default one has low capacity, since the models are large.\n",
    "MY_HUGGINGFACE_CACHE_DIR ='huggingface_cache'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=os.path.join(MY_HUGGINGFACE_CACHE_DIR, model_dir)\n",
    ")\n",
    "\n",
    "# define loss and get extra ids\n",
    "ce_loss = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id) #reduction='avg'\n",
    "ce_loss_sum = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction='sum') #reduction='sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CELL = True  # Load model\n",
    "if RUN_CELL:\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        cache_dir=os.path.join(MY_HUGGINGFACE_CACHE_DIR, model_dir),\n",
    "        **model_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_processor = eoc_datasets.ARCProcessor()\n",
    "# dataset_processor = eoc_datasets.HellaswagProcessor()\n",
    "dataset_processor = eoc_datasets.MMLUProcessor(subjects=config['mmlu_subjects'])\n",
    "# dataset_processor = eoc_datasets.BigBenchProcessor(subjects=config['bigbench_subjects'])\n",
    "data = dataset_processor.get_dataset(\n",
    "    set_partition='test', \n",
    "    # shuffle=True, # for hellaswag; index bias: the first 1000 examples have very low accuracy compared to the whole\n",
    "    # first_k_instances=1000, # see above \n",
    ")\n",
    "\n",
    "example_generator = dataset_processor.example_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
      "176it [00:01, 120.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input len max: 449, min: 21, avg: 49.07954545454545\n",
      "completion len max: 4, min: 2, avg: 3.5738636363636362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RUN_CELL = True   # set tensors_filtering_criterion by lengths\n",
    "if RUN_CELL:\n",
    "    def tensors_filtering_criterion(input_ids, completions_batch):\n",
    "        # return True\n",
    "        # remove trailing padding from completions   \n",
    "        # print('input_ids:', input_ids)\n",
    "        # print('completions_batch:', completions_batch)\n",
    "        return len(input_ids[0]) > 20 \\\n",
    "            and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 5 for completion in completions_batch]) \\\n",
    "            # and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 6 for completion in completions_batch]) \\\n",
    "            # and not all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 4 for completion in completions_batch])\n",
    "\n",
    "    gen = example_generator(data, tokenizer, mode=mode, tensors_filtering_criterion=tensors_filtering_criterion)\n",
    "    input_lens = []\n",
    "    completion_lens = []\n",
    "    for example_id, input_ids, completions_batch, label in tqdm(gen):\n",
    "        input_lens.append(len(input_ids[0]))\n",
    "        completion_lens.append(len(completions_batch[0])) # with padding, this is the max len of the completions\n",
    "    # print(f\"input len > 20 and completion len < 10  and len > 6: {sum([i > 20 and j < 6 for i, j in zip(input_lens, completion_lens)])}\")\n",
    "    # print(f\"completion len < 6: {sum([j < 6 for j in completion_lens])}\")\n",
    "    print(f\"input len max: {max(input_lens)}, min: {min(input_lens)}, avg: {sum(input_lens)/len(input_lens)}\")\n",
    "    print(f\"completion len max: {max(completion_lens)}, min: {min(completion_lens)}, avg: {sum(completion_lens)/len(completion_lens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:51,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "RUN_CELL = True  # generate baseline info and conditionals\n",
    "if RUN_CELL:\n",
    "    baseline = dict() \n",
    "    # save the label and the number of completions\n",
    "    gen = example_generator(data, tokenizer, mode, tensors_filtering_criterion=tensors_filtering_criterion)\n",
    "    for example_id, input_ids, completions_batch, label in tqdm(gen):\n",
    "        baseline[example_id] = dict()\n",
    "        baseline[example_id]['label'] = label\n",
    "        baseline[example_id]['no_completions'] = len(completions_batch)\n",
    "        baseline[example_id]['p_map'] = []\n",
    "        p_and_completion = []\n",
    "        outputs = eoc.multi_labels_forward(model, input_ids.cuda(), completions_batch.cuda())\n",
    "\n",
    "        for completion_index in range(len(completions_batch)):\n",
    "            p = -ce_loss(\n",
    "                # Only care about the tokens corresponding to the last word and omit offset tokens \n",
    "                # if the first one is <extra_id_0> and it is omitted\n",
    "                outputs.logits[completion_index][no_extra_tokens:].cuda(), \n",
    "                completions_batch[completion_index][no_extra_tokens:].cuda()\n",
    "            )\n",
    "\n",
    "            baseline[example_id]['p_map'] += [p.detach().cpu().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-offset Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:46,  3.80it/s]\n",
      "176it [00:45,  3.86it/s]\n",
      "176it [00:47,  3.70it/s]\n",
      "176it [00:45,  3.90it/s]\n",
      "176it [00:45,  3.90it/s]\n",
      "176it [00:45,  3.90it/s]\n",
      "176it [00:45,  3.89it/s]\n",
      "176it [00:45,  3.88it/s]\n",
      "176it [00:45,  3.88it/s]\n",
      "176it [00:45,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "RUN_CELL = True \n",
    "if RUN_CELL:\n",
    "    MAX_OFFSET = 10\n",
    "    p_map_offset = dict() # maps (example_id, offset, completion_index) -> avg_p\n",
    "    for offset in range(1, MAX_OFFSET+1):\n",
    "        gen = example_generator(data, tokenizer, mode, tensors_filtering_criterion=tensors_filtering_criterion)\n",
    "        for example_id, input_ids, completions_batch, label in tqdm(gen):\n",
    "            input_ids_offset, labels_offset = eoc.create_offset_sample_from_batch(\n",
    "                tokenizer,\n",
    "                input_ids,\n",
    "                completions_batch,\n",
    "                offset\n",
    "            )\n",
    "            outputs = eoc.multi_labels_forward(model, input_ids_offset.cuda(), labels_offset.cuda())\n",
    "            for completion_index in range(len(completions_batch)):\n",
    "                avg_log_p = -ce_loss(\n",
    "                    # Only care about the tokens corresponding to the original completion and omit offset tokens \n",
    "                    # if the first one is <extra_id_0> and it is omitted\n",
    "                    outputs.logits[completion_index][no_extra_tokens+offset:].cuda(), \n",
    "                    labels_offset[completion_index][no_extra_tokens+offset:].cuda()\n",
    "                )\n",
    "                p_map_offset[(example_id, offset, completion_index)] = \\\n",
    "                    avg_log_p.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAP\n",
    "\n",
    "Sequential autoregressive prompting\n",
    "\n",
    "__SAP__ is a particular type of __Ensemble of Conditionals__.\n",
    "\n",
    "It aims to augment the only conditional distribution obtained by masking the target with more distributions. The new distributions are obtained by unmasking the first __offset__ tokens from the target.\n",
    "\n",
    "An example\n",
    "\n",
    "prompt: `What is the best food? <extra_id_0>`\n",
    "\n",
    "candidates:\n",
    "\n",
    "`C1. French fries`\n",
    "\n",
    "`C2. Chicken drumlets`\n",
    "\n",
    "The baseline approach is to input `What is the best food? <extra_id_0>` to the model and obtain the probs of the C's.\n",
    "\n",
    "E.g., `P(C1) = P(French) * P(fries|French)`.\n",
    "\n",
    "SAP masks additional tokens at the start of C for different values of certain distributions.\n",
    "\n",
    "For the offset=1 case, we mask 1 extra token.\n",
    "\n",
    "prompt1: `What is the best food? French <extra_id_0>`\n",
    "\n",
    "prompt2: `What is the best food? Chicken <extra_id_0>`\n",
    "\n",
    "for candidates \n",
    "\n",
    "`C1. fries`\n",
    "\n",
    "`C2. drumlets`\n",
    "\n",
    "This gives us different values for distributions P(fries|French) and P(drumlets|Chicken), which gets put into our ensemble.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CELL = False\n",
    "if RUN_CELL:\n",
    "    baseline = dict()\n",
    "    gen = example_generator(data, tokenizer, mode, tensors_filtering_criterion=tensors_filtering_criterion, pad_to_2d_tensor=False)\n",
    "    for example_id, input_ids, completions_batch, label in tqdm(gen):\n",
    "        baseline[example_id] = dict()\n",
    "        baseline[example_id]['label'] = label\n",
    "        baseline[example_id]['no_completions'] = len(completions_batch)\n",
    "        baseline[example_id]['p_map'] = []\n",
    "        for completion_index in range(len(completions_batch)):\n",
    "            # get the sap probs for each (example, completion) pair by using offsets 0~len(completion)-2 (minus the extra_id_0 and the last token)\n",
    "            sap_probs = [] # len(sap_probs) = len(completion) - no_extra_tokens\n",
    "            for offset in range(0, no_extra_tokens-len(completions_batch[completion_index]), -1): \n",
    "                input_ids_sap, completion_ids_sap = eoc.create_offset_sample(\n",
    "                    input_ids,\n",
    "                    completions_batch[completion_index],\n",
    "                    offset # offset is negative for sap\n",
    "                )\n",
    "                # take the first no_extra_tokens + 1 tokens from completion_ids_sap: <extra_id_0> (if it exists) and the first token of the completion\n",
    "                completion_ids_sap = completion_ids_sap[:1+no_extra_tokens].unsqueeze(0)\n",
    "                outputs = model(input_ids_sap.cuda(), labels=completion_ids_sap.cuda())\n",
    "                log_p = -ce_loss(\n",
    "                    outputs.logits[0][no_extra_tokens].cuda(), # [0] to lose the batch dim, [no_extra_tokens] to skip the <extra_id_0> token\n",
    "                    completion_ids_sap[0][no_extra_tokens].cuda()\n",
    "                )\n",
    "                sap_probs.append(log_p.detach().cpu().tolist())\n",
    "            baseline[example_id]['p_map'] += [sum(sap_probs) / len(sap_probs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multispan Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:44,  3.95it/s]\n",
      "176it [00:45,  3.88it/s]\n",
      "176it [00:44,  3.95it/s]\n",
      "176it [00:45,  3.88it/s]\n",
      "176it [00:44,  3.95it/s]\n",
      "176it [00:45,  3.88it/s]\n",
      "176it [00:45,  3.91it/s]\n"
     ]
    }
   ],
   "source": [
    "RUN_CELL = True  # generate multispan conditionals\n",
    "if RUN_CELL:\n",
    "    length_gap_num_tuples = [\n",
    "        (3, 5, 1),\n",
    "        (3, 5, 2),\n",
    "        (3, 3, 1),\n",
    "        (3, 3, 2),\n",
    "        (3, 4, 1),\n",
    "        (3, 4, 2),\n",
    "        (3, 10, 1),\n",
    "    ]\n",
    "    p_map_multispan = dict()\n",
    "    for length_gap_num_tuple in length_gap_num_tuples:\n",
    "        span_length, gap_between_spans, num_spans = length_gap_num_tuple    \n",
    "        gen = example_generator(data, tokenizer, mode, tensors_filtering_criterion=tensors_filtering_criterion)\n",
    "\n",
    "        for example_id, input_ids, completions_batch, label in tqdm(gen):\n",
    "            # print(input_ids.shape)\n",
    "            # continue\n",
    "            inputs_ids_multispan, labels_multispan = eoc.create_multiple_span_sample_from_batch(\n",
    "                tokenizer,\n",
    "                input_ids[0], # squeeze 1st dim\n",
    "                completions_batch,\n",
    "                span_length,\n",
    "                gap_between_spans,\n",
    "                num_spans,\n",
    "            )\n",
    "            outputs = eoc.multi_labels_forward(model, inputs_ids_multispan.cuda(), labels_multispan.cuda())\n",
    "\n",
    "            for completion_index in range(len(completions_batch)):\n",
    "                # assert multispan samples are correct \n",
    "                assert completions_batch[completion_index].nonzero().shape[0] == \\\n",
    "                    labels_multispan[completion_index][num_spans * (span_length + 1) :].nonzero().shape[0]\n",
    "\n",
    "                avg_log_p = -ce_loss(\n",
    "                    # Only care about the tokens corresponding to the completion (see assert below)); \n",
    "                    # so the first <extra_id_0> is omitted, and for each span, the span + <extra_id_k> is omitted;\n",
    "                    # totally 1 + num_spans * (span_length + 1) tokens are omitted;\n",
    "                    # labels_multispan contains paddings.\n",
    "                    outputs.logits[completion_index][1 + num_spans * (span_length + 1) :].cuda(), \n",
    "                    labels_multispan[completion_index][1 + num_spans * (span_length + 1) :].cuda()\n",
    "                )\n",
    "                p_map_multispan[(example_id, span_length, gap_between_spans, num_spans, completion_index)] = \\\n",
    "                    avg_log_p.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_disagreement(p_and_completion_individually):\n",
    "    best_completion_indices = []\n",
    "    for p_and_completion_individual in p_and_completion_individually:\n",
    "        _, best_completion_index = max(p_and_completion_individual, key=lambda x: x[0])\n",
    "        best_completion_indices.append(best_completion_index)\n",
    "    return len(set(best_completion_indices)) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define the EOC function'''\n",
    "# Max reduction to emsemble conditionals for the same last word\n",
    "'''Max reduction to emsemble conditionals for the same last word, \n",
    "i.e., only the maximum avg_log_p is kept for each last word across different range_middle_span_length's and range_middle_to_end_gap's.\n",
    "Emsemble the baseline conditionals with the K-offset conditionals and middle-off conditionals.'''\n",
    "\n",
    "def run_eoc(offsets, length_gap_num_tuples):\n",
    "    add_baseline = True\n",
    "    add_k_offset = offsets != []\n",
    "    add_multispan = length_gap_num_tuples != []\n",
    "\n",
    "    count_correct = 0\n",
    "    count_disagreement = 0\n",
    "    for example_index in range(len(baseline)):\n",
    "        no_completions = baseline[example_index]['no_completions']\n",
    "        # Create a list of tuples (avg_log_p, completion) for each completion\n",
    "        p_and_completion = []\n",
    "        p_and_completion_individually = []\n",
    "        # add the baseline (offset = 0 from K-offset ensemble) to the list\n",
    "        if add_baseline:\n",
    "            p_and_completion_individual = [\n",
    "                (baseline[example_index]['p_map'][completion_index], completion_index)\n",
    "                for completion_index in range(no_completions)\n",
    "            ]\n",
    "            p_and_completion += p_and_completion_individual\n",
    "            p_and_completion_individually.append(p_and_completion_individual)\n",
    "            \n",
    "        # add the whole K-offset ensemble to the list\n",
    "        if add_k_offset:\n",
    "            for offset in offsets:\n",
    "                p_and_completion_individual = [\n",
    "                    (p_map_offset[(example_index, offset, completion_index)], completion_index)\n",
    "                    for completion_index in range(no_completions)\n",
    "                ]\n",
    "                p_and_completion += p_and_completion_individual\n",
    "                p_and_completion_individually.append(p_and_completion_individual)\n",
    "                \n",
    "        if add_multispan:\n",
    "            for length_gap_num in length_gap_num_tuples:\n",
    "                p_and_completion_individual = [\n",
    "                    (p_map_multispan[(example_index, *length_gap_num, completion_index)], completion_index)\n",
    "                    for completion_index in range(no_completions)\n",
    "                ]\n",
    "                p_and_completion += p_and_completion_individual\n",
    "                p_and_completion_individually.append(p_and_completion_individual)\n",
    "\n",
    "        # Find the tuple with the maximum avg_log_p; this is essentially max reduction\n",
    "        _, best_completion_index = max(p_and_completion, key=lambda x: x[0])\n",
    "        label = baseline[example_index]['label']\n",
    "        if (isinstance(label, int) and best_completion_index == label) or \\\n",
    "        (isinstance(label, list) and best_completion_index in label) :# TruthfulQA has multiple correct answers\n",
    "            count_correct += 1\n",
    "        count_disagreement += calc_disagreement(p_and_completion_individually)\n",
    "    # print(\"accuracy:\", count_correct / len(baseline))\n",
    "    return count_correct / len(baseline), count_disagreement / len(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO_DISTS: 0, avg_acc: 0.4090909090909091 avg_disagreement: 0.0\n",
      "NO_DISTS: 1, avg_acc: 0.4210858585858585 avg_disagreement: 0.3125\n",
      "NO_DISTS: 2, avg_acc: 0.4286616161616161 avg_disagreement: 0.4308712121212121\n",
      "NO_DISTS: 3, avg_acc: 0.4339150432900433 avg_disagreement: 0.4995941558441558\n",
      "NO_DISTS: 4, avg_acc: 0.4379509379509379 avg_disagreement: 0.5465818903318905\n",
      "NO_DISTS: 5, avg_acc: 0.44124278499278496 avg_disagreement: 0.5799062049062049\n",
      "NO_DISTS: 6, avg_acc: 0.4439258658008656 avg_disagreement: 0.604166666666667\n",
      "NO_DISTS: 7, avg_acc: 0.4460227272727274 avg_disagreement: 0.6223169191919191\n",
      "NO_DISTS: 8, avg_acc: 0.4476010101010101 avg_disagreement: 0.6363636363636365\n",
      "NO_DISTS: 9, avg_acc: 0.44886363636363635 avg_disagreement: 0.6477272727272727\n"
     ]
    }
   ],
   "source": [
    "RUN_CELL = True  # Run EOC\n",
    "if RUN_CELL:\n",
    "    # K-offset conditionals\n",
    "    ALL_OFFSETS = [1, 2, 3,]\n",
    "    # Multispan conditionals\n",
    "    ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "        (3, 5, 1),\n",
    "        (3, 5, 2),\n",
    "        (3, 3, 1),\n",
    "        (3, 3, 2),\n",
    "        (3, 4, 1),\n",
    "        (3, 4, 2),\n",
    "    ]\n",
    "    NO_OFFSETS = len(ALL_OFFSETS)\n",
    "    NO_MULTISPAN = len(ALL_LENGTH_GAP_NUM_TUPLES)\n",
    "    NO_DISTS_RANGE = list(range(NO_OFFSETS + NO_MULTISPAN + 1))\n",
    "    avg_accs = []\n",
    "    avg_disagreements = []\n",
    "    for NO_DISTS in NO_DISTS_RANGE: # no of distributions to ensemble\n",
    "        all_dist_ids = list(combinations(range(NO_MULTISPAN + NO_OFFSETS), NO_DISTS))\n",
    "        # shuffle and take the first 100\n",
    "        random.shuffle(all_dist_ids)\n",
    "        all_dist_ids = all_dist_ids[:500]\n",
    "        all_accs = []\n",
    "        all_disagreements = []\n",
    "        for dist_ids in all_dist_ids:\n",
    "            offsets = []\n",
    "            length_gap_num_tuples = []\n",
    "            for dist_id in dist_ids:\n",
    "                if dist_id < NO_OFFSETS:\n",
    "                    offsets.append(ALL_OFFSETS[dist_id])\n",
    "                else:\n",
    "                    length_gap_num_tuples.append(ALL_LENGTH_GAP_NUM_TUPLES[dist_id - NO_OFFSETS])            \n",
    "            acc, disagreement = run_eoc(\n",
    "                offsets,\n",
    "                length_gap_num_tuples,\n",
    "            )\n",
    "            # print offsets and length_gap_num_tuples and acc\n",
    "            # print(offsets, length_gap_num_tuples, acc)\n",
    "            all_accs.append(acc)\n",
    "            all_disagreements.append(disagreement)\n",
    "        avg_acc = sum(all_accs) / len(all_accs)\n",
    "        avg_disagreement = sum(all_disagreements) / len(all_disagreements)\n",
    "        avg_accs.append(avg_acc)\n",
    "        avg_disagreements.append(avg_disagreement)\n",
    "        # print number of dists and avg_acc\n",
    "        print(f\"NO_DISTS: {NO_DISTS}, avg_acc: {avg_acc}\", f\"avg_disagreement: {avg_disagreement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4090909090909091,\n",
       "  0.4210858585858585,\n",
       "  0.4286616161616161,\n",
       "  0.4339150432900433,\n",
       "  0.4379509379509379,\n",
       "  0.44124278499278496,\n",
       "  0.4439258658008656,\n",
       "  0.4460227272727274,\n",
       "  0.4476010101010101,\n",
       "  0.44886363636363635],\n",
       " [0.0,\n",
       "  0.3125,\n",
       "  0.4308712121212121,\n",
       "  0.4995941558441558,\n",
       "  0.5465818903318905,\n",
       "  0.5799062049062049,\n",
       "  0.604166666666667,\n",
       "  0.6223169191919191,\n",
       "  0.6363636363636365,\n",
       "  0.6477272727272727])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accs, avg_disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([0.4090909090909091,\n",
    "  0.4210858585858585,\n",
    "  0.4286616161616161,\n",
    "  0.4339150432900433,\n",
    "  0.4379509379509379,\n",
    "  0.44124278499278496,\n",
    "  0.4439258658008656,\n",
    "  0.4460227272727274,\n",
    "  0.4476010101010101,\n",
    "  0.44886363636363635],\n",
    " [0.0,\n",
    "  0.3125,\n",
    "  0.4308712121212121,\n",
    "  0.4995941558441558,\n",
    "  0.5465818903318905,\n",
    "  0.5799062049062049,\n",
    "  0.604166666666667,\n",
    "  0.6223169191919191,\n",
    "  0.6363636363636365,\n",
    "  0.6477272727272727])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
