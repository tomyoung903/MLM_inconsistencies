{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = ['UL2', 'T5']\n",
    "DATASETS = ['BigBench', 'MMLU', 'Lambada']\n",
    "avg_accs_dict = {}\n",
    "avg_disagreements_dict = {}\n",
    "# init the dictionaries\n",
    "for model in MODELS:\n",
    "    avg_accs_dict[model] = {}\n",
    "    avg_disagreements_dict[model] = {}\n",
    "    for dataset in DATASETS:\n",
    "        avg_accs_dict[model][dataset] = 0\n",
    "        avg_disagreements_dict[model][dataset] = 0\n",
    "NO_DISTS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ul2 mmlu \n",
    "-- return len(input_ids[0]) > 20 \n",
    "\n",
    "-- and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 5 for completion in completions_batch]) \\ -->\n",
    "\n",
    "-- K-offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3,]\n",
    "\n",
    "-- Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1),\n",
    "    (3, 5, 2),\n",
    "    (3, 3, 1),\n",
    "    (3, 3, 2),\n",
    "    (3, 4, 1),\n",
    "    (3, 4, 2),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['UL2']['MMLU'] = [\n",
    "    0.4577777777777778,\n",
    "    0.48246913580246914,\n",
    "    0.4885185185185184,\n",
    "    0.492116402116402,\n",
    "    0.4947442680776011,\n",
    "    0.4970723104056437,\n",
    "    0.4993650793650795,\n",
    "    0.5017283950617283,\n",
    "    0.5041975308641976,\n",
    "    0.5066666666666667\n",
    "]\n",
    "\n",
    "avg_disagreements_dict['UL2']['MMLU'] = [\n",
    "    0.0,\n",
    "    0.14962962962962967,\n",
    "    0.21432098765432095,\n",
    "    0.2562433862433862,\n",
    "    0.28649029982363305,\n",
    "    0.30952380952380937,\n",
    "    0.32772486772486775,\n",
    "    0.3424691358024692,\n",
    "    0.3545679012345679,\n",
    "    0.36444444444444446\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ul2 lambada\n",
    "return all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 6 for completion in completions_batch]) \\\n",
    "\n",
    "K-offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3, 4, 5, 6,]\n",
    "\n",
    "Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1), \n",
    "    (3, 5, 2), \n",
    "    (3, 10, 1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['UL2']['Lambada'], avg_disagreements_dict['UL2']['Lambada'] = \\\n",
    "([0.7141608391608392,\n",
    "  0.7263986013986015,\n",
    "  0.7295794483294483,\n",
    "  0.7315705128205129,\n",
    "  0.7333846708846713,\n",
    "  0.7350566100566105,\n",
    "  0.7365759240759243,\n",
    "  0.7379564879564879,\n",
    "  0.7392191142191142,\n",
    "  0.7403846153846154],\n",
    " [0.0,\n",
    "  0.18240093240093241,\n",
    "  0.2578914141414142,\n",
    "  0.3025724275724275,\n",
    "  0.3331945831945833,\n",
    "  0.35590104340104334,\n",
    "  0.37364718614718606,\n",
    "  0.38808760683760696,\n",
    "  0.4002525252525253,\n",
    "  0.41083916083916083])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ul2 BigBench \n",
    "-- return len(input_ids[0]) > 20 \n",
    "\n",
    "-- and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 5 for completion in completions_batch]) \\ -->\n",
    "\n",
    "-- K-offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3,]\n",
    "\n",
    "-- Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1),\n",
    "    (3, 5, 2),\n",
    "    (3, 3, 1),\n",
    "    (3, 3, 2),\n",
    "    (3, 4, 1),\n",
    "    (3, 4, 2),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['UL2']['BigBench'], avg_disagreements_dict['UL2']['BigBench'] = (\n",
    "  [0.39790575916230364,\n",
    "  0.40139616055846417,\n",
    "  0.39979639325189054,\n",
    "  0.4020817751184244,\n",
    "  0.4053020859303582,\n",
    "  0.40870938253137207,\n",
    "  0.41230366492146586,\n",
    "  0.41608493310063993,\n",
    "  0.4200116346713206,\n",
    "  0.42408376963350786],\n",
    " [0.0,\n",
    "  0.2577079697498546,\n",
    "  0.3810354857475276,\n",
    "  0.4567439541261532,\n",
    "  0.508310479514668,\n",
    "  0.5448350369816335,\n",
    "  0.5714285714285718,\n",
    "  0.5911867364746946,\n",
    "  0.6061663757998836,\n",
    "  0.6178010471204188]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t5 mmlu \n",
    "return len(input_ids[0]) > 20 \\\n",
    "            and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 5 for completion in completions_batch]) \\\n",
    "-- K-offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3,]\n",
    "\n",
    "-- Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1),\n",
    "    (3, 5, 2),\n",
    "    (3, 3, 1),\n",
    "    (3, 3, 2),\n",
    "    (3, 4, 1),\n",
    "    (3, 4, 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['T5']['MMLU'], avg_disagreements_dict['T5']['MMLU'] = ([0.4090909090909091,\n",
    "  0.4210858585858585,\n",
    "  0.4286616161616161,\n",
    "  0.4339150432900433,\n",
    "  0.4379509379509379,\n",
    "  0.44124278499278496,\n",
    "  0.4439258658008656,\n",
    "  0.4460227272727274,\n",
    "  0.4476010101010101,\n",
    "  0.44886363636363635],\n",
    " [0.0,\n",
    "  0.3125,\n",
    "  0.4308712121212121,\n",
    "  0.4995941558441558,\n",
    "  0.5465818903318905,\n",
    "  0.5799062049062049,\n",
    "  0.604166666666667,\n",
    "  0.6223169191919191,\n",
    "  0.6363636363636365,\n",
    "  0.6477272727272727])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t5 lambada\n",
    "return all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 6 for completion in completions_batch]) \\\n",
    "\n",
    "K-offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3, 4, 5, 6,]\n",
    "\n",
    "Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1), \n",
    "    (3, 5, 2), \n",
    "    (3, 10, 1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['T5']['Lambada'], avg_disagreements_dict['T5']['Lambada'] = ([0.6885964912280702,\n",
    "  0.6817738791423003,\n",
    "  0.6817738791423003,\n",
    "  0.6839625104427737,\n",
    "  0.6868995405179614,\n",
    "  0.6902325257588418,\n",
    "  0.6938439849624061,\n",
    "  0.6976120857699806,\n",
    "  0.7013888888888888,\n",
    "  0.7050438596491229],\n",
    " [0.0,\n",
    "  0.30007309941520466,\n",
    "  0.45300316764132564,\n",
    "  0.543076441102757,\n",
    "  0.6014863547758285,\n",
    "  0.6417867585630743,\n",
    "  0.670765455304929,\n",
    "  0.6922210038986356,\n",
    "  0.7085769980506822,\n",
    "  0.7214912280701754])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t5 BigBench \n",
    "return len(input_ids[0]) > 20 \\\n",
    "\n",
    "-- and all([len(general_utils.remove_trailing_zeros_from_1d_tensor(completion)) < 5 for completion in completions_batch]) \\ -->\n",
    "\n",
    "-- Offset conditionals\n",
    "\n",
    "ALL_OFFSETS = [1, 2, 3,]\n",
    "\n",
    "-- Multispan conditionals\n",
    "\n",
    "ALL_LENGTH_GAP_NUM_TUPLES = [\n",
    "    (3, 5, 1),\n",
    "    (3, 5, 2),\n",
    "    (3, 3, 1),\n",
    "    (3, 3, 2),\n",
    "    (3, 4, 1),\n",
    "    (3, 4, 2),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_dict['T5']['BigBench'], avg_disagreements_dict['T5']['BigBench'] = ([0.25,\n",
    "  0.2552083333333333,\n",
    "  0.25725446428571425,\n",
    "  0.25827752976190477,\n",
    "  0.2589817176870749,\n",
    "  0.2596991921768706,\n",
    "  0.26052295918367346,\n",
    "  0.2614397321428571,\n",
    "  0.26240079365079366,\n",
    "  0.26339285714285715],\n",
    " [0.0,\n",
    "  0.2702132936507937,\n",
    "  0.36414930555555547,\n",
    "  0.41592261904761896,\n",
    "  0.4500159438775509,\n",
    "  0.4743569302721088,\n",
    "  0.4926791028911567,\n",
    "  0.5071924603174602,\n",
    "  0.519345238095238,\n",
    "  0.5301339285714286]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = '/usr/share/fonts/urw-base35/NimbusMonoPS-Italic.otf'\n",
    "font_prop = fm.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the code to apply tight_layout properly to the figure, not to individual subplots\n",
    "\n",
    "# Setting up the figure for subplots again without the incorrect tight_layout call\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))  # Adjusted size for better visibility\n",
    "\n",
    "# Iterating over datasets and models to create subplots\n",
    "for i, model in enumerate(MODELS):\n",
    "    for j, dataset in enumerate(DATASETS):\n",
    "        axs[i, j].plot(range(1,11), [num * 100 for num in avg_accs_dict[model][dataset]], marker='o')\n",
    "        axs[i, j].set_title(f'{model} on {dataset}', fontsize=20)\n",
    "        axs[i, j].set_xlabel('No. ensembled conditionals', fontsize=18)\n",
    "        axs[i, j].set_ylabel('Accuracy (%)', fontsize=18)\n",
    "        # xticks range(1,11)\n",
    "        axs[i, j].set_xticks(range(1,11))\n",
    "        # plt.xticks(fontsize=25)\n",
    "        # plt.yticks(fontsize=25)\n",
    "        axs[i, j].tick_params(axis='x', labelsize=16)  # Making xticks larger\n",
    "        axs[i, j].tick_params(axis='y', labelsize=16)\n",
    "        axs[i, j].axhline(y=avg_accs_dict[model][dataset][0]*100, color='y', linestyle='--')\n",
    "        # add the word \"baseline\" at the end of the yellow line in the font of calibri\n",
    "        if i == 0 and j == 0:\n",
    "            axs[i, j].text(8, avg_accs_dict[model][dataset][0]*100 + 0.1, 'baseline', color='y', fontsize=17)\n",
    "\n",
    "        # axs[i, j].set_ylim(40, 80)  # Adjusted to accommodate both models\n",
    "\n",
    "# Applying tight_layout to the figure as a whole to ensure there's no overlap and everything fits nicely\n",
    "plt.tight_layout(pad=3.5)\n",
    "\n",
    "# save the plot as an image\n",
    "plt.savefig('eoc_accuracies.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accs_aggregated = [0 for _ in range(10)]\n",
    "for i in range(10):\n",
    "    for model in MODELS:\n",
    "        for dataset in DATASETS:\n",
    "            avg_accs_aggregated[i] += avg_accs_dict[model][dataset][i]\n",
    "    avg_accs_aggregated[i] /= 6\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.plot(range(1,11), [num * 100 for num in avg_accs_aggregated], marker='o')\n",
    "# ax.set_title('Aggregated accuracies', fontsize=20)\n",
    "ax.set_xlabel('No. ensembled conditionals', fontsize=18)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=18)\n",
    "ax.set_xticks(range(1,11))\n",
    "ax.axhline(y=avg_accs_aggregated[0]*100, color='y', linestyle='--')\n",
    "# add the word \"baseline\" at the end of the yellow line in the font of calibri\n",
    "ax.text(8, avg_accs_aggregated[0]*100 + 0.1, 'baseline', color='y', fontsize=19)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.tight_layout(pad=3.5)\n",
    "plt.savefig('eoc_aggregated_accuracies.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the disagreements but use one figure for each dataset\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # Adjusted size for better visibility\n",
    "# Iterating over datasets and models to create subplots\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "    for i, model in enumerate(MODELS):\n",
    "        axs[j].plot(range(1,11), [num * 100 for num in avg_disagreements_dict[model][dataset]], marker='o', label=model)\n",
    "        axs[j].set_title(f'{dataset}', fontsize=20)\n",
    "        axs[j].set_xlabel('No. conditionals', fontsize=18)\n",
    "        axs[j].set_ylabel('Disagreement (%)', fontsize=18)\n",
    "        # xticks range(1,11)\n",
    "        axs[j].set_xticks(range(1,11)\n",
    "        )\n",
    "        # plt.xticks(fontsize=25)\n",
    "        # plt.yticks(fontsize=25)\n",
    "        axs[j].tick_params(axis='x', labelsize=16)\n",
    "        axs[j].tick_params(axis='y', labelsize=16)\n",
    "        # axs[j].set_ylim(0, 70)  # Adjusted to accommodate both models\n",
    "        if j == 0:\n",
    "            # legend should be large\n",
    "            axs[j].legend(fontsize=16)\n",
    "# Applying tight_layout to the figure as a whole to ensure there's no overlap and everything fits nicely\n",
    "plt.tight_layout(pad=3.5)\n",
    "\n",
    "# save the plot as an image\n",
    "plt.savefig('eoc_disagreements.png')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inconsistencies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
