{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_log_p_of_option(inputs_pretokenized, word_and_punc_pair):\n",
    "    input_ids = tokenizer(inputs_pretokenized, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # print(data_appended[0]['inputs_pretokenized'])\n",
    "    # labels = tokenizer(\"<extra_id_0> \" + word_and_punc_pair + \" <extra_id_1>\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    labels = tokenizer(\"<extra_id_0> \" + word_and_punc_pair, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    # HIGHLIGHT\n",
    "    labels = labels[:, :-1]\n",
    "    # print(\"<extra_id_0> \" + id_to_word_and_punc_pairs_processed[0][2] + \" <extra_id_1>\")\n",
    "    outputs = model(input_ids, labels=labels)\n",
    "    # logits = outputs.logits\n",
    "    # loss = loss_fn(logits.view(-1, logits.shape[-1])[1:labels.shape[1]-2], labels.view(-1)[1:labels.shape[1]-2])\n",
    "    return -outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of correct predictions again using get_avg_log_p_of_options and ids_to_word_and_punc_pairs_processed\n",
    "count_correct_avg_log_p_reranking = 0\n",
    "for example_index in tqdm(range(1)): # len(data_appended)\n",
    "    input_string = data_appended[example_index]['inputs_pretokenized']\n",
    "    word_and_punc_pair_avg_log_p_max = -10000000\n",
    "    best_word_and_punc_pair =  \"\"\n",
    "    for word_and_punc_pair in id_to_word_and_punc_pairs_processed[example_index]:\n",
    "        avg_log_p = get_avg_log_p_of_options(input_string, word_and_punc_pair)\n",
    "        # print(avg_log_p)\n",
    "        if avg_log_p > word_and_punc_pair_avg_log_p_max:\n",
    "            word_and_punc_pair_avg_log_p_max = avg_log_p\n",
    "            best_word_and_punc_pair = word_and_punc_pair\n",
    "    best_word = best_word_and_punc_pair[:-1]\n",
    "    print(best_word)\n",
    "    print(best_word_and_punc_pair)\n",
    "    if best_word == data_appended[example_index]['targets_pretokenized'][0]:\n",
    "        count_correct_avg_log_p_reranking += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "# os.environ[\"TRANSFORMERS_CACHE\"] = \"/work/09127/tomyoung/ls6/LLM_cache/models--google--ul2\"\n",
    "\n",
    "# cache_dir='./models--google--ul2',\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/ul2\", cache_dir='/work/09127/tomyoung/ls6/LLM_cache/google-ul2/', low_cpu_mem_usage=True, torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "model.parallelize()                                                                                                  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/ul2\")\n",
    "\n",
    "input_string = \"[NLU] Mr. Dursley was the director of a firm called <extra_id_0>, \\\n",
    "    which made <extra_id_1>. He was a big, solid man with a bald head. \\\n",
    "        Mrs. Dursley was thin and <extra_id_2> of neck, which came in very useful as she spent \\\n",
    "            so much of her time <extra_id_3>. The Dursleys had a small son \\\n",
    "                called Dudley and <extra_id_4>\"                                           \n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "# 19,459,613,696\n",
    "# inputs = tokenizer(input_string, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(inputs, max_length=200)\n",
    "\n",
    "# print(tokenizer.decode(outputs[0]))\n",
    "# -> \"<pad><extra_id_0> Burrows<extra_id_1> a lot of money from the manufacture of a product called '' Burrows'''s ''<extra_id_2> had a lot<extra_id_3> looking down people's throats<extra_id_4> a daughter called Petunia. Dudley was a very stupid boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat, ugly boy who was always getting into trouble. He was a big, fat,\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /work/09127/tomyoung/ls6/model_inputs_1_31am.pt\n",
    "model_inputs_1_31_am = torch.load('/work/09127/tomyoung/ls6/model_inputs_1_31am.pt')\n",
    "encoder_outputs_5_13am = torch.load('/work/09127/tomyoung/ls6/encoder_outputs_5_13am.pt')\n",
    "# torch.save(model.state_dict(), '/work/09127/tomyoung/ls6/model_state_dict_1_31am.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_inputs_1_31_am: encoder_outputs, from generate, from model_kwargs, by passing prompt to the encoder\n",
    "outputs = model(encoder_outputs=model_inputs_1_31_am['encoder_outputs'], decoder_input_ids=model_inputs_1_31_am['decoder_input_ids'])\n",
    "# model_inputs_1_31_am\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Toy example'''\n",
    "input_string = \"[NLU] Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, solid man with a bald head. Mrs. Dursley was thin and blonde and more than the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbours. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere <extra_id_0>\"                                               \n",
    "inputs = tokenizer(input_string, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_length=200, num_beams=10, num_return_sequences=10)\n",
    "for i in range(1):\n",
    "    print(tokenizer.decode(outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate for 0th example\n",
    "input_string = data_appended[0]['inputs_pretokenized']\n",
    "inputs = tokenizer(input_string, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_length=100, num_beams=100, num_return_sequences=100)\n",
    "options = [tokenizer.decode(outputs[i]) for i in range(100)]\n",
    "for i in range(100):\n",
    "    print(tokenizer.decode(outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "print(len(outputs['scores']))\n",
    "for k in range(len(outputs['scores'])):\n",
    "    outputs['scores'][k]\n",
    "    probs = torch.softmax(outputs['scores'][k], dim=-1)\n",
    "    best_id = torch.argmax(probs)\n",
    "    print(best_id)\n",
    "    print(tokenizer.decode(best_id))\n",
    "    print(probs[0][best_id])\n",
    "\n",
    "# probs[0][3074]\n",
    "# [1]\n",
    "# torch.exp(outputs['scores'][1])\n",
    "# torch.argmax(torch.exp(outputs['scores'][0]))\n",
    "# # top 5\n",
    "# torch.topk(torch.exp(outputs['scores'][0]), 5)\n",
    "\n",
    "# torch.sum(torch.exp(outputs['scores'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# training\n",
    "input_ids = tokenizer(\"[NLG] A man is having a bun for <extra_id_0>\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "labels = tokenizer(\"<extra_id_0> lunch. A man is having a bun for lunch. A man is having a\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "outputs = model(input_ids=input_ids, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "\n",
    "# recover likelihood from loss\n",
    "likelihood = math.exp(-loss)\n",
    "likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def get_words_from_completions_deprecated(self, completions: List[str]):\n",
    "        '''Get the last word from each of the given completions,  Return all the words.'''\n",
    "        # if a punctuation can be found in the completion, get the word before the punctuation\n",
    "        words = []\n",
    "        for completion in completions:\n",
    "            # find the punctuation\n",
    "            for i in range(len(completion)):\n",
    "                if completion[i] in self.ENDING_PUNCTUATIONS:\n",
    "                    word = completion[:i]\n",
    "                    words.append(word)\n",
    "                    # print(words)\n",
    "                    break\n",
    "\n",
    "        # if the word starts with <pad>, remove it\n",
    "        words = [word[5:] if word.startswith(\"<pad>\") else word for word in words]\n",
    "\n",
    "        # # check it it the case that, assert that if the word starts with <extra_id_0>, ' ' follows. print the word if it is not the case\n",
    "        # for word in words:\n",
    "        #     if word.startswith(\"<extra_id_0>\") and len(word) > 13:\n",
    "        #         if word[12] != \" \":\n",
    "        #             print('word[12] != \\\" \\\"')\n",
    "        #             print(word)\n",
    "        # if the word starts with <pad>, remove it\n",
    "        word = word[5:] if word.startswith(\"<pad>\") else word\n",
    "        # if the word starts with <extra_id_0>, remove it\n",
    "        words = [word[12:] if word.startswith(\"<extra_id_0>\") else word for word in words]\n",
    "        # if the word starts with ' ', remove it\n",
    "        words = [word[1:] if word.startswith(\" \") else word for word in words]\n",
    "        # if the word ends with ' ', remove the ' '\n",
    "        words = [word[:-1] if word.endswith(\" \") else word for word in words]\n",
    "        # if the word is empty, remove it\n",
    "        words = [word for word in words if word != \"\"]\n",
    "        # if there are multiple words in word, discount it\n",
    "        words = [word for word in words if len(word.split(\" \")) == 1]\n",
    "        return words\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
